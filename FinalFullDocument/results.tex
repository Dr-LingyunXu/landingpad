% !TEX root = DesignDocument.tex

\chapter{Research Results}

This chapter describes the results and conclusions from our work on developing the UAV lander. This report should serve as the first stop for future teams interested in extending this project or conducting similar research.\\

\section{User Interface}
QGroundControl is likely the best means of generating mission files. There are definitely some problems with the application. However, it is important to remember that QGroundControl, like many of the tools we are using in this project, are currently ongoing and in development. There is an active community surrounding this project that addresses bugs, updates, and fielding questions.\\

It may be worth the time to develop a small message passing tool so that the file containing the files is not as difficult to transfer. The current process of connecting to the ODroid via network cable, logging into the ODroid, and pulling the file from the laptop from the laptop to the ODroid is clunky and slows down testing. As the team was not unable to afford the time to invest in developing this tool, this may be a good place to invest effort initially for future teams.\\

\section{Autonomous Take-off}
The take-off is solved through the functionality on the pixhawk. The pixhawk flight controller solves many of the problems of this project, so that the team was left with solving for the landing.\\

The take-off works very well, given an environment with GPS signal. There was a small issue that was found that the UAV needed to be at or very near the take-off waypoint specified in the take-off mission parameters. It is therefore much easier to drag around a laptop to connect to the UAV at the take-off point to ensure that when activated the UAV will perform the take-off mission consistently. \\

\section{Autonomous Navigation}
As mentioned in the previous section, the UAV had autonomous navigation solved with the incorporation of the pixhawk flight controller. Given an area with GPS signal, the UAV will navigate to the waypoint, and upon reaching that waypoint, load the next waypoint into as the current mission. This built-in functionality allowed the team to focus on the landing problem.\\

Future teams should be aware that when using the pixhawk, that the navigation will solve for shortest distance. Terrain will be a large issue if not considered in creating a navigation mission list. For example, if the UAV is navigating to a point that is at a higher elevation, the UAV may bounce along the ground as it navigates to the next point. This is relatively easy to address when setting up the waypoint missions through QGroundControl. The user will need to simply ensure that the height set in the missions is above the height for the entire navigation. \\

When testing the pixhawk navigation with a strong GPS signal, our tests indicated that the pixhawk was capable of consistently bringing the UAV within 1 meter of the defined navigation point. This resulted in simplifying the landing pad. However, it also merits mentioning that these results depend on accurate mapping by companies that provide the satellite maps, such as Google. If those coordinates are not consistent between the satellite map and the GPS, then, of course, the resulting navigation will be poor.\\

It may be useful in future iterations to utilize the vision approaches to localization as an end towards estimating its height. Stereo vision may be the best, but a much more costly approach to achieve this end.\\

\section{Autonomous Landing}
This was the central problem of our project. The pixhawk provided us with fairly accurate results when navigating to the landing area. This allowed us to constrain the problem from needing to locate the landing pad from a predicted distance of 10 meters to locating the landing pad from a predicted distance of 1 meter, assuming that we had a good GPS signal available.\\

As mentioned in the previous section, we need to assume that the mapping between our satellite is consistent. With that assumption, we were able to remove the landing lights from the landing pad, as we should now be at a small distance directly or nearly directly over the landing pad. We can switch over from missions being executed directly by the pixhawk to the offboard control on the Odroid, which will pass the move commands to the pixhawk via the Mavlink protocol. We can perform this action after navigating to a point much closer than previously estimated. This allowed us to contrain the landing pad problem to that of the AR tag, rather than the AR tag and landing lights.\\

The AR tag tracking, after initial difficulties, proved to be very robust and accurate, tracking distances to less than a few centimeters. However, that is with the understanding that the size of the tag is made known to the tracking node, otherwise it is not able to estimate the distance accurately. The tracking tool also provided accurate orientation information of the tag relative to the camera. The distance and orientation of the tag from the camera serves as the basis for "dragging" the UAV to the landing pad by reducing the difference between both orientation and distance. Resolving the difference means that we have landed (or close enough to, so the rotors can gently reduce power until off). \\

However, after this redesign to our approach, we encountered the obstacle which stopped us, localization. Although we were getting very accurate and consistent results with the GPS peripheral for guiding the UAV through waypoint navigation, for some reason that we could not pinpoint, our pose estimation message sent from the pixhawk to the ODroid was incredibly poor, and the move estimate was poor as well. The result of this was we would localize to an unknown and unpredictable pose and moving the UAV did not show a consistent transition across the space, making move commands poor at best, dangerous to researchers at worst.\\



\section{Conclusion}
The problem of autonomous landing has been solved many times, however, these solutions typically rely upon external observation systems in a known space (such as motion capture). It is a much more difficult problem to solve for the landing by estimating the pose of the UAV by other means, such as using vision. Although the authors of the SVO package which we were relying upon for localization do not guarantee results, we felt that we should have at least had some limited success in worst case, if we had set up the package properly. That in mind we feel that the possible issues to the failure of our project lay in:
\begin{enumerate}
\item Camera Type. We are using an inexpensive camera, but a camera without a wide lens and a low frame rate. These two issues may be causing the lack of feature acquisition to match across subsequent image frames, causing us to lose our relative position from our initial localization. Use of a different camera may solve this issue.
\item Number of Features. There are a few different parameters that can be adjusted to limit the number of features needed and to cap the number of features tracked. Setting the needed number of features low may initially seem like a good idea because we get a rapid localization, those features may be missing in the next frame after the camera has moved. Setting the cap to the number of features being tracked to a very large number has the drawback of contributing to a large increase in processing time to perform RANSAC, as well as compare features between frames to find matches. Unfortunately, this issue will require a good deal of time to tweak the values to find a good balance that delivers reliable tracking with a minimum of processing time.
\item Shutter Type. This is another potential issue. There are different types of shutters that have different effects, or can have, on the image that results. A rolling shutter is very common for inexpensive web cameras. A rolling shutter will update cells line by line. More expensive cameras may feature a global shutter, where the cells are updated all at once and so avoid the potential blurring effect that may result from motion. The team feels that cheaper solutions are better, but perhaps this may be an issue where there is no current compromise. This would be the last area of exploration for post review, as it is not as accessible for testing as the previous two.
\end{enumerate}
The pieces to solving this project are contained here. The UAV is built and flying autonomously with the pixhawk. The camera is able to detect the position of the tag accurately so that we can measure our position from the landing pad and make the necessary corrections to land the craft on the landing pad with the correct orientation so that it may recharge before its next flight.\\



\section{Further work}  
There are many different ways that this work can be extended from where our team has ended its research. The team has gathered these few possiblities:
\begin{enumerate}
\item Solve how to localize in a GPS denied environment. This was our final obstacle, and certainly another group may utilize the work we have done and solve for the localization with vision, or perhaps another approach.
\item Add another camera and add the task of obstacle avoidance by means of computer vision. This project has assumed that in take-off, navigation, and landing, the UAV has an unobstructed path. In actual deployment, it may not be the case that the craft will be unobstructed along its path. Certain terrain features, such as rocks, trees, buildings may not be available on the map, and the craft will be unable to proceed as is.
\item Solve for navigation in GPS denied environments. The UAV may be deployed and navigate to areas where GPS signal is not available. The UAV should be able to continue to navigate to the location where it believes those coordinates lay. This would be of great assistance to application where navigation across steep terrain or dense canopy may prevent access to a reliable GPS signal.
\end{enumerate}

These extensions are difficult problems that are compounded by the amount of processor available, as well as the draw that a processing has on power consumption, reducing the overall flight time of the UAV. However, this project should provide a firm base for launching in any of these directions.